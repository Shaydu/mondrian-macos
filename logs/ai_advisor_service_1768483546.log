[INFO] Python executable: /Users/shaydu/dev/mondrian-macos/mondrian/venv/bin/python3
[INFO] Python version: 3.12.2
[INFO] Working directory: /Users/shaydu/dev/mondrian-macos
[INFO] Environment variables:
[INFO]   MLX_USE_CPU=<not set>
[INFO]   CUDA_VISIBLE_DEVICES=<not set>
[INFO]   PYTORCH_ENABLE_MPS_FALLBACK=<not set>
[INFO] MLX default device explicitly set to: Device(gpu, 0)
[INFO] MLX configured to use GPU backend (Metal)
[INFO] MLX backend initialized successfully (GPU mode)
[INFO] AI Advisor Service v2.0-JSON starting...
[INFO] Using JSON output format (converted to HTML for backward compatibility)
[INFO] Using base64 encoding for all images
[INFO] Using MLX backend for vision analysis
[INFO] MLX Mode: ENABLED
[INFO] MLX Model: mlx-community/Qwen3-VL-4B-Instruct-4bit
[INFO] Model timeout: 300s
[INFO] RAG Service URL: http://127.0.0.1:5400
[INFO] RAG Default: ENABLED (from RAG_ENABLED env var)
[INFO] System prompt loaded from database (2751 characters)
AI Advisor Service starting up...
  Port: 5100
  DB Path: /Users/shaydu/dev/mondrian-macos/mondrian/mondrian.db
  MLX Model: mlx-community/Qwen3-VL-4B-Instruct-4bit
  Job service URL: http://127.0.0.1:5005
  Current working directory: /Users/shaydu/dev/mondrian-macos
  Image Encoding: BASE64 (all platforms)
[INFO] Initializing service with model_mode=base
[INFO] Model Strategy: BASE (no fine-tuning)
[INFO] Loading MLX model: mlx-community/Qwen3-VL-4B-Instruct-4bit...
[INFO] First load - model cache is empty, will download and load
[INFO] Testing Metal GPU access...
[INFO] ✓ Metal GPU is available and working
Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]Fetching 14 files: 100%|██████████| 14/14 [00:00<00:00, 130780.08it/s]
Traceback (most recent call last):
  File "/Users/shaydu/dev/mondrian-macos/mondrian/ai_advisor_service.py", line 2548, in <module>
    success = initialize_service(
              ^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/ai_advisor_service.py", line 482, in initialize_service
    _MLX_MODEL, _MLX_PROCESSOR, _IS_FINE_TUNED = get_mlx_model(lora_path=None, use_lora=False)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/ai_advisor_service.py", line 331, in get_mlx_model
    _MLX_MODEL, _MLX_PROCESSOR = load(MLX_MODEL)
                                 ^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/mlx_vlm/utils.py", line 312, in load
    processor = load_processor(model_path, True, eos_token_ids=eos_token_id, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/mlx_vlm/utils.py", line 370, in load_processor
    processor = AutoProcessor.from_pretrained(model_path, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/models/auto/processing_auto.py", line 391, in from_pretrained
    return processor_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/processing_utils.py", line 1396, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/processing_utils.py", line 1482, in _get_arguments_from_pretrained
    sub_processor = auto_processor_class.from_pretrained(pretrained_model_name_or_path, **kwargs)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py", line 741, in from_pretrained
    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 1757, in from_pretrained
    return cls._from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py", line 2006, in _from_pretrained
    init_kwargs = cls.convert_to_native_format(**init_kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/tokenization_utils_tokenizers.py", line 118, in convert_to_native_format
    tokenizer_json = json.load(tokenizer_handle)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py", line 293, in load
    return loads(fp.read(),
           ^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
               ^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
