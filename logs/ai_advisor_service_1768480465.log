[INFO] Python executable: /Users/shaydu/dev/mondrian-macos/mondrian/venv/bin/python3
[INFO] Python version: 3.12.2
[INFO] Working directory: /Users/shaydu/dev/mondrian-macos
[INFO] Environment variables:
[INFO]   MLX_USE_CPU=<not set>
[INFO]   CUDA_VISIBLE_DEVICES=<not set>
[INFO]   PYTORCH_ENABLE_MPS_FALLBACK=<not set>
[INFO] MLX default device explicitly set to: Device(gpu, 0)
[INFO] MLX configured to use GPU backend (Metal)
[INFO] MLX backend initialized successfully (GPU mode)
[INFO] AI Advisor Service v2.0-JSON starting...
[INFO] Using JSON output format (converted to HTML for backward compatibility)
[INFO] Using base64 encoding for all images
[INFO] Using MLX backend for vision analysis
[INFO] MLX Mode: ENABLED
[INFO] MLX Model: mlx-community/Qwen3-VL-4B-Instruct-4bit
[INFO] Model timeout: 300s
[INFO] RAG Service URL: http://127.0.0.1:5400
[INFO] RAG Default: ENABLED (from RAG_ENABLED env var)
[INFO] System prompt loaded from database (2751 characters)
AI Advisor Service starting up...
  Port: 5100
  DB Path: /Users/shaydu/dev/mondrian-macos/mondrian/mondrian.db
  MLX Model: mlx-community/Qwen3-VL-4B-Instruct-4bit
  Job service URL: http://127.0.0.1:5005
  Current working directory: /Users/shaydu/dev/mondrian-macos
  Image Encoding: BASE64 (all platforms)
[INFO] Initializing service with model_mode=fine_tuned
[INFO] Model Strategy: FINE-TUNED
[INFO] Loading LoRA adapter from: ./adapters/ansel
[INFO] Loading MLX model: mlx-community/Qwen3-VL-4B-Instruct-4bit...
[INFO] Testing Metal GPU access...
[INFO] ✓ Metal GPU is available and working
Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]Fetching 14 files: 100%|██████████| 14/14 [00:00<00:00, 211986.48it/s]
Using `use_fast=True` but `torchvision` is not available. Falling back to the slow image processor.
[ERROR] Failed to load MLX model: Received a NoneType for argument video_processor, but a BaseVideoProcessor was expected.
[ERROR] MLX backend is not available on this system
Traceback (most recent call last):
  File "/Users/shaydu/dev/mondrian-macos/mondrian/ai_advisor_service.py", line 2494, in <module>
    success = initialize_service(
              ^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/ai_advisor_service.py", line 481, in initialize_service
    _MLX_MODEL, _MLX_PROCESSOR, _IS_FINE_TUNED = get_mlx_model(lora_path=lora_path, use_lora=True)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/ai_advisor_service.py", line 323, in get_mlx_model
    _MLX_MODEL, _MLX_PROCESSOR = load(MLX_MODEL)
                                 ^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/mlx_vlm/utils.py", line 312, in load
    processor = load_processor(model_path, True, eos_token_ids=eos_token_id, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/mlx_vlm/utils.py", line 370, in load_processor
    processor = AutoProcessor.from_pretrained(model_path, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/models/auto/processing_auto.py", line 391, in from_pretrained
    return processor_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/processing_utils.py", line 1398, in from_pretrained
    return cls.from_args_and_dict(args, processor_dict, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/processing_utils.py", line 1167, in from_args_and_dict
    processor = cls(*args, **valid_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/models/qwen3_vl/processing_qwen3_vl.py", line 76, in __init__
    super().__init__(image_processor, tokenizer, video_processor, chat_template=chat_template)
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/processing_utils.py", line 594, in __init__
    self.check_argument_for_proper_class(attribute_name, arg)
  File "/Users/shaydu/dev/mondrian-macos/mondrian/venv/lib/python3.12/site-packages/transformers/processing_utils.py", line 675, in check_argument_for_proper_class
    raise TypeError(
TypeError: Received a NoneType for argument video_processor, but a BaseVideoProcessor was expected.
