[INFO] Python executable: /Library/Frameworks/Python.framework/Versions/3.12/bin/python3
[INFO] Python version: 3.12.2
[INFO] Working directory: /Users/shaydu/dev/mondrian-macos
[INFO] Environment variables:
[INFO]   MLX_USE_CPU=<not set>
[INFO]   CUDA_VISIBLE_DEVICES=<not set>
[INFO]   PYTORCH_ENABLE_MPS_FALLBACK=<not set>
[INFO] MLX default device explicitly set to: Device(gpu, 0)
[INFO] MLX configured to use GPU backend (Metal)
[INFO] MLX backend initialized successfully (GPU mode)
[INFO] AI Advisor Service v2.0-JSON starting...
[INFO] Using JSON output format (converted to HTML for backward compatibility)
[INFO] Using base64 encoding for all images
[INFO] Using MLX backend for vision analysis
[INFO] MLX Mode: ENABLED
[INFO] MLX Model: mlx-community/Qwen3-VL-4B-Instruct-4bit
[INFO] Model timeout: 300s
[INFO] RAG Service URL: http://127.0.0.1:5400
[INFO] RAG Default: ENABLED (from RAG_ENABLED env var)
[INFO] System prompt loaded from database (2751 characters)
AI Advisor Service starting up...
  Port: 5100
  DB Path: /Users/shaydu/dev/mondrian-macos/mondrian/mondrian.db
  MLX Model: mlx-community/Qwen3-VL-4B-Instruct-4bit
  Job service URL: http://127.0.0.1:5005
  Current working directory: /Users/shaydu/dev/mondrian-macos
  Image Encoding: BASE64 (all platforms)
[INFO] Initializing service with model_mode=fine_tuned
[INFO] Model Strategy: FINE-TUNED
[INFO] Loading LoRA adapter from: ./adapters/ansel
[INFO] Loading MLX model: mlx-community/Qwen3-VL-4B-Instruct-4bit...
[INFO] Testing Metal GPU access...
[INFO] âœ“ Metal GPU is available and working
Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]Fetching 14 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 47934.90it/s]
[INFO] MLX model loaded in 2.96s using GPU backend and cached
[INFO] MLX default device: Device(gpu, 0)
[INFO] âœ“ GPU acceleration confirmed active
[INFO] Loading LoRA adapter from: ./adapters/ansel
[INFO] LoRA Config: rank=None, alpha=None, dropout=None
[INFO] Applying LoRA adapter from: ./adapters/ansel
#trainable params: 16.515072 M || all params: 4022.468096 M || trainable%: 0.411%
[INFO] LoRA adapter successfully applied to model
[INFO] Service initialized successfully. Fine-tuned: True
[INFO] Model Strategy: fine_tuned
[INFO] Fine-Tuned: True
[INFO] Service ready on http://0.0.0.0:5100
AI Advisor Service running on port 5100...
 * Serving Flask app 'ai_advisor_service'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5100
 * Running on http://10.0.0.131:5100
[33mPress CTRL+C to quit[0m
/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
