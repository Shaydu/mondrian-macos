[INFO] AI Advisor Service v1.13-BASE64-HTTP-OLLAMA starting...
[INFO] Using base64 encoding for all images
[INFO] Using Ollama HTTP API endpoint
[INFO] Backend: mlx
[INFO] Model: lmstudio-community/Qwen3-VL-4B-Instruct-MLX-4bit
[INFO] Model timeout: 600s
[INFO] System prompt loaded from database (3277 characters)
[INFO] Pre-loading MLX model at startup for better performance...
[INFO] This may take 30-60 seconds on first run...
[INFO] Loading model: lmstudio-community/Qwen3-VL-4B-Instruct-MLX-4bit
[INFO] âœ“ MLX model loaded and cached successfully!
AI Advisor Service starting up...
  Port: 5100
  DB Path: mondrian.db
  Model: lmstudio-community/Qwen3-VL-4B-Instruct-MLX-4bit
  Ollama URL: http://127.0.0.1:11434
  Job service URL: http://10.0.0.131:5005
  Current working directory: /Users/shaydu/dev/mondrian-macos/mondrian
  Image Encoding: BASE64 (all platforms)
AI Advisor Service running on port 5100...
 * Serving Flask app 'ai_advisor_service_v1.13'
 * Debug mode: off
