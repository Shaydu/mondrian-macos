
[1m[94m
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Mondrian Linux/CUDA RTX 3060 Setup Verification       â•‘
â•‘  Test Suite                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[0m

[1m[94m============================================================[0m
[1m[94m             Test 1: NVIDIA Driver Installation             [0m
[1m[94m============================================================[0m

  | NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
[92mâœ“ PASS[0m: nvidia-smi command executed successfully

[1m[94m============================================================[0m
[1m[94m            Test 2: GPU Detection and Properties            [0m
[1m[94m============================================================[0m

[92mâœ“ PASS[0m: CUDA is available (found 1 GPU device(s))
[94mâ„¹ INFO[0m: GPU 0: NVIDIA GeForce RTX 3060
[94mâ„¹ INFO[0m:   VRAM: 11.63 GB
[94mâ„¹ INFO[0m:   Compute Capability: 8.6
[92mâœ“ PASS[0m: RTX 3060 detected as expected
[92mâœ“ PASS[0m: VRAM sufficient (11.63 GB >= 8 GB)

[1m[94m============================================================[0m
[1m[94m             Test 3: CUDA Version Compatibility             [0m
[1m[94m============================================================[0m

[94mâ„¹ INFO[0m: CUDA Version: 12.1
[92mâœ“ PASS[0m: CUDA 12 is compatible (>= CUDA 12.1 recommended)

[1m[94m============================================================[0m
[1m[94m             Test 4: PyTorch CUDA Functionality             [0m
[1m[94m============================================================[0m

[94mâ„¹ INFO[0m: Created and computed with GPU tensors
[94mâ„¹ INFO[0m: Result shape: torch.Size([10, 10]), dtype: torch.float32
[92mâœ“ PASS[0m: PyTorch CUDA operations working correctly

[1m[94m============================================================[0m
[1m[94m       Test 5: HuggingFace Transformers Installation        [0m
[1m[94m============================================================[0m

[94mâ„¹ INFO[0m: Transformers version: 4.57.5
[92mâœ“ PASS[0m: HuggingFace Transformers installed

[1m[94m============================================================[0m
[1m[94m             Test 6: PEFT Library Installation              [0m
[1m[94m============================================================[0m

[94mâ„¹ INFO[0m: PEFT version: 0.18.1
[92mâœ“ PASS[0m: PEFT (LoRA) library installed

[1m[94m============================================================[0m
[1m[94m               Test 7: Required Dependencies                [0m
[1m[94m============================================================[0m

[92mâœ“ PASS[0m: torch is installed
[92mâœ“ PASS[0m: torchvision is installed
[92mâœ“ PASS[0m: transformers is installed
[92mâœ“ PASS[0m: accelerate is installed
[92mâœ“ PASS[0m: peft is installed
[92mâœ“ PASS[0m: safetensors is installed
[92mâœ“ PASS[0m: bitsandbytes is installed
[92mâœ“ PASS[0m: flask is installed
[92mâœ“ PASS[0m: flask_cors is installed
[92mâœ“ PASS[0m: pillow is installed
[92mâœ“ PASS[0m: opencv is installed
[92mâœ“ PASS[0m: numpy is installed

[1m[94m============================================================[0m
[1m[94m                 Test 8: GPU Memory Status                  [0m
[1m[94m============================================================[0m

[94mâ„¹ INFO[0m: Total VRAM: 12.00 GB
[94mâ„¹ INFO[0m: Used VRAM: 0.59 GB (4.9%)
[94mâ„¹ INFO[0m: Free VRAM: 11.03 GB
[92mâœ“ PASS[0m: Sufficient VRAM available for model loading

[1m[94m============================================================[0m
[1m[94m             Test 9: Virtual Environment Status             [0m
[1m[94m============================================================[0m

[92mâœ“ PASS[0m: Virtual environment active: /home/doo/dev/mondrian-macos/venv

[1m[94m============================================================[0m
[1m[94m                Test 10: Directory Structure                [0m
[1m[94m============================================================[0m

[92mâœ“ PASS[0m: Directory 'mondrian' exists
[92mâœ“ PASS[0m: Directory 'scripts' exists
[92mâœ“ PASS[0m: Directory 'test' exists
[92mâœ“ PASS[0m: Directory 'tools' exists
[92mâœ“ PASS[0m: Directory 'docs' exists

[1m[94m============================================================[0m
[1m[94m                        Test Summary                        [0m
[1m[94m============================================================[0m

  [92mâœ“ PASS[0m  NVIDIA Drivers
  [92mâœ“ PASS[0m  GPU Detection
  [92mâœ“ PASS[0m  CUDA Version
  [92mâœ“ PASS[0m  PyTorch CUDA
  [92mâœ“ PASS[0m  Transformers
  [92mâœ“ PASS[0m  PEFT Library
  [92mâœ“ PASS[0m  Dependencies
  [92mâœ“ PASS[0m  Memory Status
  [92mâœ“ PASS[0m  Virtual Environment
  [92mâœ“ PASS[0m  Directory Structure

[1mResults: 10/10 tests passed[0m

[92m[1mâœ“ All tests passed! RTX 3060 Linux CUDA setup is ready.[0m

Next steps:
  1. Start the AI Advisor service:
     python mondrian/ai_advisor_service_linux.py --port 5100
  2. Test the service in another terminal:
     curl http://localhost:5100/health
