{
  "models": {
    "qwen3-4b-instruct": {
      "name": "Qwen3-VL-4B-Instruct",
      "model_id": "Qwen/Qwen3-VL-4B-Instruct",
      "description": "Fast, optimized for speed. Good for standard photography analysis.",
      "adapter": "./training/lora_adapters/ansel_qwen3_4b_v3/epoch_20",
      "speed": "fast",
      "quality": "good",
      "reasoning": false,
      "tokens_per_sec": "25-35 (BF16)",
      "generation": {
        "max_new_tokens": 1200,
        "num_beams": 1,
        "do_sample": false,
        "repetition_penalty": 1.0,
        "temperature": 0.7,
        "top_p": 0.95
      }
    },
    "qwen3-4b-thinking": {
      "name": "Qwen3-VL-4B-Thinking",
      "model_id": "Qwen/Qwen3-VL-4B-Thinking",
      "description": "Shows step-by-step reasoning. Great for detailed analysis with visible thinking.",
      "adapter": "./adapters/ansel_qwen3_4b_thinking/epoch_10",
      "speed": "slower",
      "quality": "excellent",
      "reasoning": true,
      "tokens_per_sec": "15-25 (BF16)",
      "generation": {
        "max_new_tokens": 1500,
        "num_beams": 1,
        "do_sample": false,
        "repetition_penalty": 1.0,
        "temperature": 0.7,
        "top_p": 0.95
      }
    },
    "qwen3-8b-instruct": {
      "name": "Qwen3-VL-8B-Instruct",
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "description": "Larger model, better quality than 4B. Fast.",
      "adapter": "./adapters/ansel_qwen3_8b_instruct/epoch_10",
      "speed": "fast",
      "quality": "excellent",
      "reasoning": false,
      "tokens_per_sec": "20-30 (BF16)",
      "generation": {
        "max_new_tokens": 1200,
        "num_beams": 1,
        "do_sample": false,
        "repetition_penalty": 1.0,
        "temperature": 0.7,
        "top_p": 0.95
      }
    },
    "qwen3-8b-thinking": {
      "name": "Qwen3-VL-8B-Thinking",
      "model_id": "Qwen/Qwen3-VL-8B-Thinking",
      "description": "Largest model with reasoning. Best quality and visible thinking.",
      "adapter": "./adapters/ansel_qwen3_8b_thinking/epoch_10",
      "speed": "slower",
      "quality": "best",
      "reasoning": true,
      "tokens_per_sec": "12-20 (BF16)",
      "generation": {
        "max_new_tokens": 1500,
        "num_beams": 1,
        "do_sample": false,
        "repetition_penalty": 1.0,
        "temperature": 0.7,
        "top_p": 0.95
      }
    }
  },
  "defaults": {
    "model_preset": "qwen3-4b-instruct",
    "mode": "lora",
    "description": "Default: Qwen3-VL-4B-Instruct with LoRA adapter for fast, good quality analysis",
    "generation_profile": "sampling"
  },
  "generation_profiles": {
    "fast_greedy": {
      "description": "Fastest inference with greedy decoding (testing)",
      "max_new_tokens": 1200,
      "num_beams": 1,
      "do_sample": false,
      "repetition_penalty": 1.0,
      "temperature": 0.7,
      "top_p": 0.95
    },
    "beam_search": {
      "description": "Balanced speed/quality with beam search",
      "max_new_tokens": 1200,
      "num_beams": 2,
      "do_sample": false,
      "repetition_penalty": 1.2,
      "temperature": 0.7,
      "top_p": 0.95
    },
    "sampling": {
      "description": "Higher quality with sampling (slower)",
      "max_new_tokens": 1500,
      "num_beams": 1,
      "do_sample": true,
      "temperature": 0.8,
      "top_p": 0.95,
      "repetition_penalty": 1.2
    }
  }
}
