{
  "runtime_config": {
    "token_limits": {
      "default_max_new_tokens": 5000,
      "inference_backend_default": 2500,
      "min_tokens": 500,
      "max_tokens": 8000,
      "description": "Dynamic token generation limits. Adjust these to control max output length."
    },
    "streaming": {
      "update_interval_seconds": 3,
      "description": "How often to send status updates during analysis (in seconds)"
    },
    "description": "Runtime configuration for token limits and streaming behavior"
  },
  "models": {
    "qwen3-4b-instruct": {
      "name": "Qwen3-VL-4B-Instruct",
      "model_id": "Qwen/Qwen3-VL-4B-Instruct",
      "description": "Trained on 223 images including CADB dataset and Ansel Adams examples. 15 epochs.",
      "adapter": "./training/training/lora_adapters/ansel_qwen3_4b_instruct/epoch_15",
      "speed": "fast",
      "quality": "good",
      "reasoning": false,
      "tokens_per_sec": "25-35 (BF16)"
    },
    "qwen3-4b-thinking": {
      "name": "Qwen3-VL-4B-Thinking",
      "model_id": "Qwen/Qwen3-VL-4B-Thinking",
      "description": "Shows step-by-step reasoning. Great for detailed analysis with visible thinking.",
      "adapter": "./adapters/ansel_qwen3_4b_thinking/epoch_10",
      "speed": "slower",
      "quality": "excellent",
      "reasoning": true,
      "tokens_per_sec": "15-25 (BF16)"
    },
    "qwen3-8b-instruct": {
      "name": "Qwen3-VL-8B-Instruct",
      "model_id": "Qwen/Qwen3-VL-8B-Instruct",
      "description": "Larger model, better quality than 4B. Fast.",
      "adapter": "./adapters/ansel_qwen3_8b_instruct/epoch_10",
      "speed": "fast",
      "quality": "excellent",
      "reasoning": false,
      "tokens_per_sec": "20-30 (BF16)"
    },
    "qwen3-8b-thinking": {
      "name": "Qwen3-VL-8B-Thinking",
      "model_id": "Qwen/Qwen3-VL-8B-Thinking",
      "description": "Largest model with reasoning. Best quality and visible thinking.",
      "adapter": "./adapters/ansel_qwen3_8b_thinking/epoch_10",
      "speed": "slower",
      "quality": "best",
      "reasoning": true,
      "tokens_per_sec": "12-20 (BF16)"
    }
  },
  "defaults": {
    "model_preset": "qwen3-4b-instruct",
    "mode": "lora",
    "generation_profile": "optimized",
    "enable_rag": true,
    "system_prompt_key": "system_prompt",
    "description": "Default: Qwen3-VL-4B-Instruct with LoRA adapter, 4-beam search with 2500 tokens, RAG enabled, 6-dimension prompt"
  },
  "prompts": {
    "system_prompt": {
      "dimensions": 6,
      "target_tokens": "4000-4500",
      "description": "Full 6-dimension analysis: Composition, Lighting, Focus & Sharpness, Depth & Perspective, Visual Balance, Emotional Impact"
    },
    "system_prompt_3": {
      "dimensions": 3,
      "target_tokens": "2000-2500",
      "description": "Fast 3-dimension analysis: Composition, Lighting, Emotional Impact"
    }
  },
  "rag": {
    "max_reference_images": 3,
    "max_reference_quotes": 3,
    "description": "Maximum number of reference images and quotes to include per LLM response"
  },
  "generation_profiles": {
    "optimized": {
      "max_new_tokens": 3500,
      "num_beams": 2,
      "do_sample": false,
      "repetition_penalty": 1.15,
      "early_stopping": true,
      "description": "2-beam search with 3500 token limit for detailed, actionable feedback"
    },
    "fast_greedy": {
      "max_new_tokens": 1500,
      "num_beams": 1,
      "do_sample": false,
      "repetition_penalty": 1.15,
      "description": "Greedy decoding, fast inference (~2-3x faster than beam search)"
    },
    "beam_search": {
      "max_new_tokens": 3500,
      "num_beams": 4,
      "do_sample": false,
      "repetition_penalty": 1.15,
      "early_stopping": true,
      "description": "4-beam search for highest quality detailed feedback"
    },
    "sampling": {
      "max_new_tokens": 1500,
      "num_beams": 1,
      "do_sample": true,
      "temperature": 0.7,
      "top_p": 0.9,
      "top_k": 50,
      "repetition_penalty": 1.15,
      "description": "Nucleus sampling for more varied responses"
    },
    "ultra_fast": {
      "max_new_tokens": 1200,
      "num_beams": 1,
      "do_sample": false,
      "repetition_penalty": 1.05,
      "description": "Maximum speed: greedy decoding with minimal tokens. Best for quick iterations and testing. ~3-5x faster than beam search."
    }
  }
}